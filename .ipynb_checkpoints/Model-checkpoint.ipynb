{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fff6eb6-f002-4934-a924-22f5ac9e16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f19695-4b68-4037-a245-032573bf2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(X, y, num_classes=None):\n",
    "    # Transpose to shape (samples, time, channels): (N, 800, 62)\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "\n",
    "    # Normalize across time axis (feature-wise standardization)\n",
    "    n_samples, n_timepoints, n_channels = X.shape\n",
    "    X = X.reshape(-1, n_channels)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = X.reshape(n_samples, n_timepoints, n_channels)\n",
    "\n",
    "    # One-hot encode labels\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(y))\n",
    "    y_cat = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    return X.astype(np.float32), y_cat.astype(np.float32)\n",
    "\n",
    "def load_data():\n",
    "    data_paths = [\n",
    "        r\"C:\\Users\\Noman\\Desktop\\Github\\CTL_Scratch\\Data_Prep_and_Data\\1\\1_1_Windowed_Data.npy\",\n",
    "        r\"C:\\Users\\Noman\\Desktop\\Github\\CTL_Scratch\\Data_Prep_and_Data\\2\\1_2_Windowed_Data.npy\",\n",
    "        r\"C:\\Users\\Noman\\Desktop\\Github\\CTL_Scratch\\Data_Prep_and_Data\\3\\1_3_Windowed_Data.npy\",\n",
    "    ]\n",
    "\n",
    "    label_paths = [\n",
    "        r\"C:\\Users\\Noman\\Desktop\\Github\\CTL_Scratch\\Data_Prep_and_Data\\1\\1_1_Windowed_Label.npy\",\n",
    "        r\"C:\\Users\\Noman\\Desktop\\Github\\CTL_Scratch\\Data_Prep_and_Data\\2\\1_2_Windowed_Label.npy\",\n",
    "        r\"C:\\Users\\Noman\\Desktop\\Github\\CTL_Scratch\\Data_Prep_and_Data\\3\\1_3_Windowed_Label.npy\",\n",
    "    ]\n",
    "\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    for d_path, l_path in zip(data_paths, label_paths):\n",
    "        data = np.load(d_path)  # shape: (n_samples, 62, 800)\n",
    "        labels = np.load(l_path)  # shape: (n_samples,)\n",
    "        all_data.append(data)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    X = np.concatenate(all_data, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8a42ba-a1f7-4e7d-86eb-19ae1ca90960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class Flatten(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.reshape(inputs, (tf.shape(inputs)[0], -1))\n",
    "\n",
    "\n",
    "class ConTL(tf.keras.Model):\n",
    "    def __init__(self, input_shape, lstm_hidden_size, n_units, n_classes):\n",
    "        super(ConTL, self).__init__()\n",
    "\n",
    "        # CNN\n",
    "        self.cnn = models.Sequential([\n",
    "            layers.Conv1D(64, kernel_size=4, strides=2, activation=None, input_shape=input_shape),\n",
    "            layers.Conv1D(64, kernel_size=4, strides=2, activation=None),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "        ])\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.fc_layer = layers.Dense(n_units)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=2, key_dim=n_units)\n",
    "        self.ffn = models.Sequential([\n",
    "            layers.Dense(n_units, activation='relu'),\n",
    "            layers.Dense(n_units)\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.dropout2 = layers.Dropout(0.1)\n",
    "\n",
    "        # BiLSTM\n",
    "        self.lstm1 = layers.Bidirectional(layers.LSTM(lstm_hidden_size, return_sequences=True))\n",
    "        self.lstm2 = layers.Bidirectional(layers.LSTM(lstm_hidden_size))\n",
    "\n",
    "        # Final FC Layer\n",
    "        self.output_layer = layers.Dense(n_classes)\n",
    "\n",
    "    def transformer_encoder(self, x):\n",
    "        attn_output = self.attention(x, x)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # CNN\n",
    "        x = self.cnn(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        # Expand dims for Transformer: (batch_size, seq_len=1, d_model)\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # LSTM\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x)\n",
    "\n",
    "        # Final output\n",
    "        output = self.output_layer(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa69747-adfb-4851-ae64-ac7034b68144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 19s 68ms/step - loss: 2.2292 - accuracy: 0.2560 - val_loss: 1.3857 - val_accuracy: 0.2764\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 1.3791 - accuracy: 0.2875 - val_loss: 1.3853 - val_accuracy: 0.2714\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 1.3721 - accuracy: 0.3043 - val_loss: 1.3881 - val_accuracy: 0.2704\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 1.3582 - accuracy: 0.3184 - val_loss: 1.4000 - val_accuracy: 0.2693\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 1.3634 - accuracy: 0.3521 - val_loss: 1.3959 - val_accuracy: 0.2774\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 1.3533 - accuracy: 0.3395 - val_loss: 1.3894 - val_accuracy: 0.2492\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 1.3791 - accuracy: 0.3519 - val_loss: 1.4628 - val_accuracy: 0.2513\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 1.3617 - accuracy: 0.3521 - val_loss: 1.4226 - val_accuracy: 0.2563\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 1.3329 - accuracy: 0.3742 - val_loss: 1.5387 - val_accuracy: 0.2754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c89d8b8f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data\n",
    "X_raw, y_raw = load_data()\n",
    "\n",
    "# Preprocess and split\n",
    "X, y = preprocess_data(X_raw, y_raw, num_classes=4)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model input shape = (time_steps=800, channels=62)\n",
    "input_shape = (X.shape[1], X.shape[2])  # (800, 62)\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Initialize model\n",
    "model = ConTL(input_shape=input_shape, lstm_hidden_size=64, n_units=128, n_classes=n_classes)\n",
    "\n",
    "# ðŸ”§ Initialize model by calling it on dummy input\n",
    "_ = model(tf.zeros((1, *input_shape)))  # e.g., shape (1, 800, 62)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=100,\n",
    "          batch_size=32,\n",
    "          callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671de646-47f3-4b08-bbc2-d9f4b1031be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4971, 62, 800) (4971,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6f7990-06b2-4e19-a177-02df00d12111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4971, 800, 62) (4971, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_data(X, y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18eee09-66e9-425f-a0d7-8f0c12b2071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 800, 64)           11968     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 800, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 400, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 400, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 400, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 400, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 200, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,268\n",
      "Trainable params: 90,884\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 22s 141ms/step - loss: 1.3946 - accuracy: 0.2674 - val_loss: 1.3843 - val_accuracy: 0.2734\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 8s 121ms/step - loss: 1.3710 - accuracy: 0.3154 - val_loss: 1.3947 - val_accuracy: 0.2794\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 7s 118ms/step - loss: 1.3682 - accuracy: 0.3053 - val_loss: 1.4083 - val_accuracy: 0.2985\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 6s 103ms/step - loss: 1.3547 - accuracy: 0.3182 - val_loss: 1.4113 - val_accuracy: 0.2824\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 6s 102ms/step - loss: 1.3436 - accuracy: 0.3370 - val_loss: 1.4302 - val_accuracy: 0.2503\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 7s 114ms/step - loss: 1.3269 - accuracy: 0.3531 - val_loss: 1.4656 - val_accuracy: 0.2472\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 1.3159 - accuracy: 0.3561 - val_loss: 1.5133 - val_accuracy: 0.2442\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 7s 118ms/step - loss: 1.3163 - accuracy: 0.3581 - val_loss: 1.4433 - val_accuracy: 0.2482\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 1.2898 - accuracy: 0.3735 - val_loss: 1.4204 - val_accuracy: 0.2533\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 1.2786 - accuracy: 0.3969 - val_loss: 1.4462 - val_accuracy: 0.2432\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 7s 116ms/step - loss: 1.2832 - accuracy: 0.3868 - val_loss: 1.4281 - val_accuracy: 0.2442\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 7s 111ms/step - loss: 1.2638 - accuracy: 0.4009 - val_loss: 1.4345 - val_accuracy: 0.2432\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 1.2695 - accuracy: 0.4085 - val_loss: 1.4331 - val_accuracy: 0.2814\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 1.2755 - accuracy: 0.3994 - val_loss: 1.4606 - val_accuracy: 0.2824\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 9s 141ms/step - loss: 1.2592 - accuracy: 0.4150 - val_loss: 1.4096 - val_accuracy: 0.2864\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 1.2378 - accuracy: 0.4251 - val_loss: 1.4110 - val_accuracy: 0.2894\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 8s 133ms/step - loss: 1.2351 - accuracy: 0.4364 - val_loss: 1.4321 - val_accuracy: 0.2824\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 1.2230 - accuracy: 0.4323 - val_loss: 1.4331 - val_accuracy: 0.2834\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 8s 128ms/step - loss: 1.2250 - accuracy: 0.4328 - val_loss: 1.4258 - val_accuracy: 0.3025\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 9s 145ms/step - loss: 1.2170 - accuracy: 0.4462 - val_loss: 1.4281 - val_accuracy: 0.2633\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 8s 129ms/step - loss: 1.1854 - accuracy: 0.4618 - val_loss: 1.4218 - val_accuracy: 0.2794\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 9s 148ms/step - loss: 1.2660 - accuracy: 0.4047 - val_loss: 1.4378 - val_accuracy: 0.2784\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 1.2098 - accuracy: 0.4429 - val_loss: 1.4515 - val_accuracy: 0.2784\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 9s 139ms/step - loss: 1.1899 - accuracy: 0.4532 - val_loss: 1.4703 - val_accuracy: 0.2824\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 8s 133ms/step - loss: 1.1773 - accuracy: 0.4628 - val_loss: 1.4591 - val_accuracy: 0.3166\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 10s 153ms/step - loss: 1.1924 - accuracy: 0.4552 - val_loss: 1.4565 - val_accuracy: 0.2854\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 8s 127ms/step - loss: 1.1804 - accuracy: 0.4643 - val_loss: 1.4637 - val_accuracy: 0.2744\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 9s 141ms/step - loss: 1.1898 - accuracy: 0.4590 - val_loss: 1.4245 - val_accuracy: 0.2824\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 1.1523 - accuracy: 0.4839 - val_loss: 1.4292 - val_accuracy: 0.2523\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 9s 148ms/step - loss: 1.1412 - accuracy: 0.4834 - val_loss: 1.4349 - val_accuracy: 0.2925\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Build and train model\n",
    "model = build_cnn_lstm(input_shape=X_train.shape[1:], num_classes=y.shape[1])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a51d2a-49d8-48ab-af8c-97c7284bc693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 30ms/step - loss: 1.4349 - accuracy: 0.2925\n",
      "Test Accuracy: 0.2925\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2614a-f93d-4cf7-ad2f-33bf1b649e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
